<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bargav Jayaraman</title>
    <link>https://bargavjayaraman.github.io/</link>
    <description>Recent content on Bargav Jayaraman</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://bargavjayaraman.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Example Talk</title>
      <link>https://bargavjayaraman.github.io/talk/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s &lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Defense Against Attribute Inference</title>
      <link>https://bargavjayaraman.github.io/post/ai_defense_results/</link>
      <pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/post/ai_defense_results/</guid>
      <description>

&lt;h2 id=&#34;jun-27-2022-vanilla-model-training&#34;&gt;[Jun 27, 2022] Vanilla Model Training&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;predicting-hispanic-ethnicity-on-texas-100x-i&#34;&gt;Predicting &lt;em&gt;Hispanic&lt;/em&gt; ethnicity on Texas-100X (I)&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Threat Setting:&lt;/strong&gt; &lt;br&gt;
Training distirbution is general data set distribution except the most populous hospitals.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;u&gt;Adversarial Knowledge&lt;/u&gt;:&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;High:&lt;/em&gt; Adversary knows all but one record from training set.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Medium:&lt;/em&gt; Adversary knows the training distribution (i.e. can sample records with no intersection with training set)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Low:&lt;/em&gt; Adversary knows a skewed distribution (that has records from hospitals with highest number of patients)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;img/texas-100x.jpg&#34; width=&#34;100%&#34;&gt;&lt;/center&gt;
&lt;center&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Patient records distribution in Texas-100X, sorted with respect to hospital population.&lt;/center&gt;&lt;/p&gt;

&lt;h4 id=&#34;model-uses-race-as-a-training-feature&#34;&gt;Model uses &lt;em&gt;race&lt;/em&gt; as a training feature&lt;/h4&gt;

&lt;p&gt;As reported in the paper draft, the model trained on Texas-100X data set uses the race attribute as a feature which could have a positive correlation with the ethnicity attribute. Regardless of this, it is still useful to compare the attribute inference attacks with the imputation (IP) attack in this setting.&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;&lt;strong&gt;Hypothesis:&lt;/strong&gt; Passing WB$\cdot$IP as a feature to WB$\diamondsuit$IP&amp;rsquo;s decision tree should improve the attack.&lt;/summary&gt;
    &lt;strong&gt;Remark:&lt;/strong&gt; The resulting WB$\square$IP attack does better, but only for the low adversarial knowledge setting where the adversary doesn&amp;rsquo;t know the training distribution. Still for most cases, WB$\square$IP doesn&amp;rsquo;t do better than WB$\cdot$IP.
&lt;/details&gt;&lt;/p&gt;

&lt;p&gt;&lt;details&gt;
    &lt;summary&gt;&lt;strong&gt;Hypothesis:&lt;/strong&gt; There should be no gap between attribute inference and imputation with knowledge of train set.&lt;/summary&gt;
    &lt;strong&gt;Remark:&lt;/strong&gt; Though there is a gap, this gap is reduced when imputation is trained with class label.
&lt;/details&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;WB$\cdot$IP multiplies the outputs of WB and IP &lt;br&gt;
WB$\diamondsuit$IP uses a decision tree model to combine WB and IP &lt;br&gt;
WB$\square$IP uses a decision tree model to combine WB, IP and WB$\cdot$IP &lt;br&gt;
IP$^\dagger$ is the imputation with access to class label&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Test)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Random&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;76 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;74 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;73 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;75 $\pm$ 4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;72 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;92 $\pm$ 2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;81 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;82 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;72 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;82 $\pm$ 4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;79 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;76 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;89 $\pm$ 1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;82 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;68 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;77 $\pm$ 5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;82 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;81 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;77 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;center&gt;&lt;strong&gt;Table 1:&lt;/strong&gt; PPV (%) for predicting top-100 records on Texas-100X. Candidate set is drawn from general distribution.&lt;/center&gt;&lt;/p&gt;

&lt;h4 id=&#34;model-doesn-t-have-access-to-race&#34;&gt;Model doesn&amp;rsquo;t have access to &lt;em&gt;race&lt;/em&gt;&lt;/h4&gt;

&lt;p&gt;Here we study the impact of removing race from the model training. Since race and ethnicity have implicit correlation, it would be more realistic to assume the adversary trying to infer ethnicity would not know the race of the query record.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Test)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Random&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;28 $\pm$ 0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;38 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;43 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;43 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;39 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;42 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;42 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;43 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;40 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;44 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;46 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;46 $\pm$ 4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;47 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;49 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;46 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;49 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;45 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;46 $\pm$ 6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;55 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;65 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;63 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;49 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;55 $\pm$ 1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;61 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;55 $\pm$ 7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;68 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;39 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;54 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;62 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;59 $\pm$ 8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;58 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;43 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;53 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;59 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;60 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;44 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;56 $\pm$ 2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;48 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;51 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;59 $\pm$ 9&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;56 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;38 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;55 $\pm$ 2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;43 $\pm$ 7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;50 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;55 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;38 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;56 $\pm$ 1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;center&gt;&lt;strong&gt;Table 2:&lt;/strong&gt; PPV (%) for predicting top-100 records on Texas-100X. Candidate set is drawn from general distribution.&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; From the results in Table 2, we can see the impact of removing race attribute on ethnicity inference. The imputation PPV drops from ~80% to ~40%.&lt;/p&gt;

&lt;h3 id=&#34;predicting-hispanic-ethnicity-on-texas-100x-ii&#34;&gt;Predicting &lt;em&gt;Hispanic&lt;/em&gt; ethnicity on Texas-100X (II)&lt;/h3&gt;

&lt;p&gt;Here we consider the scenario where the training data comes from skewed distribution, while an adversary (in low adversarial knowledge setting) might have access to the general pupulation distribution.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Threat Setting:&lt;/strong&gt; &lt;br&gt;
Training distirbution is a skewed distribution limited to records from most populous hospitals.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;u&gt;Adversarial Knowledge&lt;/u&gt;:&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;High:&lt;/em&gt; Adversary knows all but one record from training set.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Medium:&lt;/em&gt; Adversary knows the training distribution (i.e. can sample records with no intersection with training set)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;em&gt;Low:&lt;/em&gt; Adversary knows the general data set distribution except the most populous hospitals.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;model-uses-race-as-a-training-feature-1&#34;&gt;Model uses &lt;em&gt;race&lt;/em&gt; as a training feature&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Test)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Random&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;89 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;92 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;93 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;74 $\pm$ 4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;77 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;75 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;89 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;93 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;94 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;96 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;95 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;97 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;95 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;90 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;94 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;90 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;97 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;94 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;96 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;95 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;96 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;95 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;95 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;95 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;92 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;82 $\pm$ 5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;97 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;93 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;95 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;92 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;89 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;center&gt;&lt;strong&gt;Table 3:&lt;/strong&gt; PPV (%) for predicting top-100 records on Texas-100X. Candidate set is drawn from &lt;em&gt;skewed&lt;/em&gt; distribution.&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; As shown in Table 3, IP$^\dagger$ performs slightly worse than IP. Hence the class label seems to have a negative correlation with the Hispanic ethnicity in this setting where training records come from a skewed distribution.&lt;/p&gt;

&lt;h4 id=&#34;model-doesn-t-have-access-to-race-1&#34;&gt;Model doesn&amp;rsquo;t have access to &lt;em&gt;race&lt;/em&gt;&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;High Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Med Adv (Test)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Train)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Low Adv (Test)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Random&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22 $\pm$ 0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;67 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;68 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;69 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;45 $\pm$ 4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;71 $\pm$ 5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;61 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;47 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;44 $\pm$ 6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;53 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;55 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;53 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;56 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;51 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;54 $\pm$ 5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;91 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;70 $\pm$ 2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;89 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;61 $\pm$ 6&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;60 $\pm$ 8&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;90 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;59 $\pm$ 8&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;56 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\cdot$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;82 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;60 $\pm$ 4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\diamondsuit$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;86 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;87 $\pm$ 3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84 $\pm$ 2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;59 $\pm$ 7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64 $\pm$ 8&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;WB$\square$IP$^\dagger$&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;88 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;85 $\pm$ 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57 $\pm$ 7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;62 $\pm$ 6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;center&gt;&lt;strong&gt;Table 4:&lt;/strong&gt; PPV (%) for predicting top-100 records on Texas-100X. Candidate set is drawn from &lt;em&gt;skewed&lt;/em&gt; distribution.&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark:&lt;/strong&gt; Similar to previous case, race&amp;rsquo;s correlation to ethnicity has a huge impact on the inference task.&lt;/p&gt;

&lt;h3 id=&#34;comments&#34;&gt;Comments&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Merlin, Morgan, and the Importance of Thresholds and Priors</title>
      <link>https://bargavjayaraman.github.io/post/revisiting-mi/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/post/revisiting-mi/</guid>
      <description>

&lt;p&gt;Machine learning poses a substantial risk that adversaries will be able to discover information that the model does not intend to reveal. One set of methods by which consumers can learn this sensitive information, known broadly as &lt;em&gt;membership inference&lt;/em&gt; attacks, predicts whether or not a query record belongs to the training set. A basic membership inference attack involves an attacker with a given record and black-box access to a model who tries to determine whether
said record was a member of the model&amp;rsquo;s training set.&lt;/p&gt;

&lt;p&gt;Unlike much of the existing research on the membership inference, though, these particular results focus on what are considered &amp;ldquo;realistic assumptions,&amp;rdquo; including conditions with skewed priors (wherein members only make up a small fraction of the candidate pool) and conditions with adversaries that select accuracy-improving inference thresholds based on specific attack goals. These new assumptions help to answer the question of how differential privacy can be implemented to provide meaningful privacy guarantees in practice.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;img/image1.png&#34; width=&#34;80%&#34;&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;threshold-selection&#34;&gt;Threshold Selection&lt;/h2&gt;

&lt;p&gt;In order to classify a record as either a member or a non-member,
there must be a threshold that converts a real number output from a
test into a Boolean. We develop a procedure to select a threshold,
&amp;phi;, that allows the adversary to achieve as much privacy leakage as
possible while staying beneath a maximum false positive rate, &amp;alpha;.&lt;/p&gt;

&lt;p&gt;This selection procedure can be applied to any membership inference
attack, including Yeom&amp;rsquo;s attack. The original version of this
attack classifies a record as a member if its per-instance-loss is
less than the expected training loss, whereas this new approach
selects members based on a threshold &lt;em&gt;&amp;phi;&lt;/em&gt;, which can be set
to target a particular false positive rate.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img alt=&#34;&#34; src=&#34;img/image2.png&#34; width=&#34;80%&#34;&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-merlin-attack&#34;&gt;The Merlin Attack&lt;/h2&gt;

&lt;p&gt;In addition to this new selection procedure, we introduce a new attack
known as Merlin, which stands for &lt;b&gt;ME&lt;/b&gt;asuring &lt;b&gt;R&lt;/b&gt;elative &lt;b&gt;L&lt;/b&gt;oss &lt;b&gt;I&lt;/b&gt;n &lt;b&gt;N&lt;/b&gt;eighborhood. Instead of per-instance-loss, this attack uses the
direction of change of per-instance-loss when the record is slightly
perturbed with noise. Merlin operates based on the intuition that, as
a result of overfitting, member records are more likely to be near
local minima than non-member records. This suggests that for members,
loss is more likely to increase at perturbed points near the original,
whereas it is equally likely to increase or decrease for
non-members. For each record, a small amount of random Gaussian noise
is added and the change of loss direction is recorded. This process is
repeated multiple times and Merlin infers membership based on the
fraction of times the loss increases.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img alt=&#34;&#34; src=&#34;img/image3.png&#34; width=&#34;80%&#34;&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-morgan-attack&#34;&gt;The Morgan Attack&lt;/h2&gt;

&lt;p&gt;Since Yeom and Merlin use different information to make their
membership inferences, they do not always identify the same records as
members; some members are more vulnerable to one attack than the
other. Visualizing a combination of the attacks&amp;rsquo; results
suggests that by eliminating the results with a very low
per-instance-loss, a combination of the two may produce an improved
PPV. The intuition here is that extremely low per-instance-losses may
result in Merlin&amp;rsquo;s identification of a local minimum where there
is in fact a near global minimum (which is much less strongly
correlated with membership).&lt;/p&gt;

&lt;p&gt;The Morgan (&lt;b&gt;M&lt;/b&gt;easuring l&lt;b&gt;O&lt;/b&gt;ss, &lt;b&gt;R&lt;/b&gt;elatively
&lt;B&gt;G&lt;/b&gt;reater &lt;b&gt;A&lt;/b&gt;round &lt;b&gt;N&lt;/b&gt;eighborhood) attack uses three
different thresholds: a lower threshold on per-instance loss (&lt;em&gt;&amp;phi;&lt;/em&gt;&lt;sub&gt;&lt;em&gt;L&lt;/em&gt;&lt;/sub&gt;),
an upper threshold on per-instance loss (&lt;em&gt;&amp;phi;&lt;/em&gt;&lt;sub&gt;&lt;em&gt;U&lt;/em&gt;&lt;/sub&gt;),
and a threshold on the ratio as used by Merlin (&lt;em&gt;&amp;phi;&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt;). If a
record has a per-instance-loss that falls between &lt;em&gt;&amp;phi;&lt;/em&gt;&lt;sub&gt;&lt;em&gt;L&lt;/em&gt;&lt;/sub&gt; and &lt;em&gt;&amp;phi;&lt;/em&gt;&lt;sub&gt;&lt;em&gt;U&lt;/em&gt;&lt;/sub&gt;, and has a Merlin ratio of at least &lt;em&gt;&amp;phi;&lt;/em&gt;&lt;sub&gt;&lt;em&gt;M&lt;/em&gt;&lt;/sub&gt;, Morgan identifies it as a member.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img alt=&#34;&#34; src=&#34;img/image4.jpg&#34; width=&#34;50%&#34;&gt;&lt;br&gt;
&lt;div class=&#34;caption&#34;&gt;&lt;/p&gt;

&lt;p&gt;The figure shows the per-instance loss and Merlin ratio for
Purchase-100X (and expanded version of the Purchase-100 dataset that
we created for our experiments). Members and nonmembers are denoted
by orange and purple points respectively. The boxes show the
thresholds found by the threshold selection process (without access to
the training data, but with the same data distribution), and
illustrate the regions where members are identified by Morgan with
very high confidence (PPV &amp;sim;1). (See &lt;a href=&#34;https://arxiv.org/abs/2005.10881&#34;&gt;paper&lt;/a&gt; for details, and more result.)
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&#34;imbalanced-priors&#34;&gt;Imbalanced Priors&lt;/h2&gt;

&lt;p&gt;Previous work on membership inference attacks assumes a candidate pool
where half of the candidates are members. For most settings,
especially ones where there is a serious privacy risk for an
individual of being identified as a dataset member, this assumption is
unrealistic. It is important to understand how well inference attacks
work when the adversary&amp;rsquo;s candidate pool has a different prior
probability of being amember.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img alt=&#34;&#34; src=&#34;img/image5.png&#34; width=&#34;60%&#34;&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Here, the candidate pool from which the attacker attempts to select
members has &lt;em&gt;&amp;gamma;&lt;/em&gt; times more non-member records than member
records. As shown above, even in situations that other papers do not
consider, wherein there are many times more non-members than members,
attacks are able to attain a high rate of positively-identified
members.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The Merlin and Morgan attacks can reliably identify members even in
situations with imbalanced priors where other attacks fail to show
meaningful inference risk.&lt;/p&gt;

&lt;p&gt;There remains a large gap between what can be guaranteed using
differential privacy methods, and what can be inferred using known
inference attacks. This means better inference attacks may exist, and
our results show that there are concrete ways to improve attacks
(e.g., our threshold-selection procedure) and to incorporate more
information to improve attacks. We are especially interested in
attacks that produce extremely high PPVs, even if this is only for a
small fraction of candidates, since for most scenarios this is where
the most serious privacy risks lie.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Full paper:&lt;/strong&gt; Bargav Jayaraman, Lingxiao Wang, Katherine Knipmeyer,
Quanquan Gu, David Evans. &lt;a href=&#34;https://arxiv.org/abs/2005.10881&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;Revisiting Membership Inference Under
Realistic Assumptions&lt;/em&gt;&lt;/a&gt; (&lt;a href=&#34;https://arxiv.org/abs/2005.10881&#34; target=&#34;_blank&#34;&gt;arXiv&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Code:&lt;/strong&gt; &lt;a href=&#34;https://github.com/bargavj/EvaluatingDPML&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;https://github.com/bargavj/EvaluatingDPML&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Revisiting Membership Inference Under Realistic Assumptions</title>
      <link>https://bargavjayaraman.github.io/publication/revisiting-mi/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/revisiting-mi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Xbox One X HDD Loading Test</title>
      <link>https://bargavjayaraman.github.io/post/xbox_one_x_hdd_loading_test/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/post/xbox_one_x_hdd_loading_test/</guid>
      <description>

&lt;p&gt;With the advent of 4K UHD and HDR games, it is not uncommon nowadays that your Xbox One X stock HDD of 1 TB gets filled quickly with just a handful of games. And my case is no different, within one year of purchasing the console, I already ran out of hard disk space. So I did what any gamer would do in my situation; I ordered a &lt;a href=&#34;https://www.bestbuy.com/site/seagate-expansion-4tb-external-usb-3-0-portable-hard-drive-black/4820200.p?skuId=4820200&#34; target=&#34;_blank&#34;&gt;4TB external hard drive&lt;/a&gt; [Yay!]. Now that I planned to transfer some games from my internal HDD to the external HDD, curiosity plagued the researcher in me! Is the internal HDD faster at loading games than the external HDD? Or is it the other way around? Both schools of thoughts have their own reasoning. On one hand internal HDD is, well, internal. It uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Serial_ATA&#34; target=&#34;_blank&#34;&gt;SATA 3&lt;/a&gt; connection supporting upto 600 MB/s of bandwidth. On the other hand, external HDD uses &lt;a href=&#34;https://en.wikipedia.org/wiki/USB_3.0&#34; target=&#34;_blank&#34;&gt;USB 3.0&lt;/a&gt; connection supporting upto 625 MB/s of bandwidth. Both the hard drives have rotation speed of 5400 RPM, so it is still an apple to apple comparison.&lt;/p&gt;

&lt;p&gt;Note that this idea of comparing the loading speeds of internal and external HDDs is not novel. There are already many videos and blogs on this topic - be it for computers or consoles. What&amp;rsquo;s new in this blog is to evaluate this in a [&lt;em&gt;cough&lt;/em&gt;] scientific way - using hypothesis testing. Let&amp;rsquo;s get into a [somewhat] scientific evaluation!&lt;/p&gt;

&lt;h2 id=&#34;hypothesis-testing-on-game-loading-task&#34;&gt;Hypothesis testing on game loading task&lt;/h2&gt;

&lt;p&gt;Game loading time is measured (in &lt;em&gt;mm:ss&lt;/em&gt;) as the time taken to launch the game - from clicking on the game till the point where the player gets the control of the playable character, as shown in this &lt;a href=&#34;https://www.youtube.com/watch?v=MQ_pDLMI650&#34; target=&#34;_blank&#34;&gt;video&lt;/a&gt;. I recorded the loading time for 10 AAA title games, with the exception of Forza Motorsport 7, where I recorded till the point where the main menu appears. Launching a race involves lot of manual selection process, which could add more variability in recording time.&lt;/p&gt;

&lt;p&gt;The null hypothesis is $H_0:$ &lt;em&gt;&amp;ldquo;game loading time of internal HDD is same as that of external HDD&amp;rdquo;&lt;/em&gt;, and the alternate hypothesis is $H_a:$ &lt;em&gt;&amp;ldquo;game loading time of internal HDD is not same as that of external HDD&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&#34;experimental-observations&#34;&gt;Experimental observations&lt;/h2&gt;

&lt;p&gt;The game loading times are reported in the table below.
&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;Game Title&lt;/th&gt; &lt;th&gt;Internal HDD Time &lt;br&gt;(&lt;i&gt;mm:ss&lt;/i&gt;)&lt;/th&gt; &lt;th&gt;External HDD Time &lt;br&gt;(&lt;i&gt;mm:ss&lt;/i&gt;)&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Assassin&amp;rsquo;s Creed Origins&lt;/td&gt; &lt;td&gt;01:48.50&lt;/td&gt; &lt;td&gt;01:51.05&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Tomb Raider&lt;/td&gt; &lt;td&gt;00:50.95&lt;/td&gt; &lt;td&gt;00:41.78&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Rise of Tomb Raider&lt;/td&gt; &lt;td&gt;02:32.14&lt;/td&gt; &lt;td&gt;02:15.54&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Shadow of Tomb Raider&lt;/td&gt; &lt;td&gt;01:36.63&lt;/td&gt; &lt;td&gt;01:24.30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Halo Master Chief Collection&lt;/td&gt; &lt;td&gt;00:57.29&lt;/td&gt; &lt;td&gt;00:46.89&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Batman: Arkham Assylum&lt;/td&gt; &lt;td&gt;01:09.88&lt;/td&gt; &lt;td&gt;01:03.00&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Batman: Arkham City&lt;/td&gt; &lt;td&gt;01:13.94&lt;/td&gt; &lt;td&gt;01:12.30&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Batman: Arkham Knight&lt;/td&gt; &lt;td&gt;01:39.64&lt;/td&gt; &lt;td&gt;01:36.14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Forza Horizon 4&lt;/td&gt; &lt;td&gt;02:33.74&lt;/td&gt; &lt;td&gt;02:04.31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Forza Motorsport 7&lt;/td&gt; &lt;td&gt;01:00.00&lt;/td&gt; &lt;td&gt;00:50.69&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;Since there is a one-to-one correspondence of each game, we can use &lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/t-test/&#34; target=&#34;_blank&#34;&gt;paired sample T-test&lt;/a&gt;.
We can calculate the $t$-value for the paired sample T-test using a simple formula:&lt;/p&gt;

&lt;p&gt;$t-value = \frac{D_1 / N}{\sqrt{\frac{D_2 - D_1^2 / N}{N(N-1)}}}$&lt;/p&gt;

&lt;p&gt;Where $N$ is the total number of games ($N = 10$), $D_1$ is the total difference between loading times of internal and external HDDs ($D_1 = 96.71$) and $D_2$ is the total squared difference between loading times of internal and external HDDs ($D_2 = 1641.4153$). The calculated $t$-value comes out to be 3.4526 which is greater than the threshold $t$-value of 3.250 for a significance threshold of 0.005. Hence we can reject the null hypothesis $H_0$ with 99.5% confidence and conclude that [&lt;em&gt;my&lt;/em&gt;] external HDD is faster than the internal HDD of [&lt;em&gt;my&lt;/em&gt;] Xbox One X.&lt;/p&gt;

&lt;h2 id=&#34;disclaimer-on-the-validity-of-results&#34;&gt;Disclaimer on the validity of results&lt;/h2&gt;

&lt;p&gt;The above results are for a single loading of each game, and the loading time might vary by a few seconds across multiple runs. Ideally, average loading time should be used for such experiments. However, it should be noted that if the same game is loaded multiple times, the consequent loading will be faster due to &lt;em&gt;memory caching&lt;/em&gt;. To avoid caching, games should be loaded in an alternative fashion. Finally, it is important to put a disclaimer that the reported results are for my hardware, and these results &lt;em&gt;might&lt;/em&gt; vary for others. So take it with a grain of salt! :P&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Keeping the above disclaimer in mind, I conclude that my external HDD loads games faster than the stock HDD of my Xbox One X. This benefit might be attributed to the extra 25 MB/s bandwidth of USB 3.0 interface used by the external HDD.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Efficient Privacy-Preserving Nonconvex Optimization</title>
      <link>https://bargavjayaraman.github.io/publication/nonconvex-optimization/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/nonconvex-optimization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evaluating Differentially Private Machine Learning in Practice</title>
      <link>https://bargavjayaraman.github.io/publication/evaluating-dpml/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/evaluating-dpml/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/JAGhqbY_U50&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization</title>
      <link>https://bargavjayaraman.github.io/publication/dp-erm/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/dp-erm/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/rwyWiDyVmjE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Evaluating Differentially Private Machine Learning in Practice</title>
      <link>https://bargavjayaraman.github.io/post/evaluating-dpml-results/</link>
      <pubDate>Mon, 08 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/post/evaluating-dpml-results/</guid>
      <description>

&lt;p&gt;With the recent advances in composition of differential private mechanisms, the research community has been able to achieve meaningful deep learning with privacy budgets in single digits. R&amp;#x00E8;nyi differential privacy (RDP) is one mechanism that provides tighter composition which is widely used because of its implementation in TensorFlow Privacy (recently, Gaussian differential privacy (GDP) has shown a tighter analysis for low privacy budgets, but it was not yet available when we did this work). But the central question that remains to be answered is: &lt;em&gt;how private are these methods in practice?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In this blog post, we answer this question by empirically evaluating the privacy leakage of differential private neural networks via membership inference attacks. This work appeared in &lt;a href=&#34;https://www.usenix.org/conference/usenixsecurity19&#34; target=&#34;_blank&#34;&gt;USENIX Security&amp;rsquo;19&lt;/a&gt; (full paper: &lt;a href=&#34;https://www.cs.virginia.edu/~evans/pubs/usenix2019/evaluatingdp.pdf&#34; target=&#34;_blank&#34;&gt;PDF&lt;/a&gt;, &lt;a href=&#34;https://www.youtube.com/watch?v=JAGhqbY_U50&#34; target=&#34;_blank&#34;&gt;talk video&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;training-differentially-private-models&#34;&gt;Training Differentially Private Models&lt;/h2&gt;

&lt;p&gt;We train two-layer neural network models using a training procedure similar to the popular &lt;a href=&#34;https://arxiv.org/pdf/1607.00133.pdf&#34; target=&#34;_blank&#34;&gt;DPSGD&lt;/a&gt; procedure. The training and test sets consist of seperate 10,000 instances randomly sampled from the &lt;a href=&#34;https://www.cs.toronto.edu/~kriz/cifar.html&#34; target=&#34;_blank&#34;&gt;CIFAR-100&lt;/a&gt; data set.&lt;/p&gt;

&lt;p&gt;The figure below shows the accuracy loss of private models trained with na&amp;#x00EF;ve composition (NC) and R&amp;#x00E8;nyi differential privacy (RDP) with respect to a non-private model. As expected, models trained with RDP achieve much better utility when compared to the models trained with NC. To give a comparison, models trained with RDP achieve 53% accuracy loss at \(\epsilon = 10\), whereas the models trained with NC achieve the same utility at \(\epsilon = 500\). Due to the tighter composition, RDP mechanism adds much lesser noise when compared to NC mechanism for the same privacy budget.&lt;/p&gt;

&lt;p&gt;This is great, but what about the privacy leakage?






&lt;figure&gt;

&lt;img src=&#34;img/acc_loss.jpg&#34; &gt;


&lt;/figure&gt;
&lt;/p&gt;

&lt;h2 id=&#34;privacy-comes-at-a-cost&#34;&gt;Privacy comes at a cost&lt;/h2&gt;

&lt;p&gt;To estimate privacy leakage, we implement the membership inference attack of &lt;a href=&#34;https://arxiv.org/pdf/1709.01604.pdf&#34; target=&#34;_blank&#34;&gt;Yeom et al&lt;/a&gt; and use their membership advantage metric, which is given as the difference between true positive rate (TPR) and false positive rate (FPR) of detecting whether a given instance is a part of the training set. This metric lies between 0 and 1, where 0 signifies no privacy leakage.&lt;/p&gt;

&lt;p&gt;As the figure below depicts, there is a clear trade-off between privacy and utility. While the RDP mechanism achieves higher utility, it also suffers from higher privacy leakage. The attack achieves around 0.40 membership advantage score against model trained with RDP at \(\epsilon = 1000\), with a positive predictive value (PPV) of 74%. While this is less than the privacy leakage of non-private model (highlighted in the figure below), it is a significant amount of leakage. On the other hand, the model has almost no utility at lower privacy budgets where the privacy leakage is low.






&lt;figure&gt;

&lt;img src=&#34;img/priv_leak.jpg&#34; &gt;


&lt;/figure&gt;

A more interesting observation is that we only have tight theoretical worst case guarantees on membership advantage for \(\epsilon &amp;lt; 1\), at which point the models neither have any utility nor have any empirical privacy leakage. While the attacks only give a lower bound on the privacy leakage, the huge gap between the theoretical upper bound and the empirical lower bound suggests that there could be stronger attacks  in practice.&lt;/p&gt;

&lt;h2 id=&#34;leakage-is-not-random&#34;&gt;Leakage is not random&lt;/h2&gt;

&lt;p&gt;We have shown above that the membership inference attack can be effective against a model trained with RDP at \(\epsilon = 1000\). The members identified by the attacker are not due to the randomness in machine learning process. To show this, we run run the above experiment multiple times and note the fraction of members that are repeatedly identified across different runs. The figure below shows the results. The attacker is able to identify almost a quarter of the training records with more than 82% PPV across five runs. If the leakage was due to the randomness, we would have expected a trend similar to the dotted line.






&lt;figure&gt;

&lt;img src=&#34;img/multi_run.jpg&#34; &gt;


&lt;/figure&gt;
&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The differential privacy research community has come a long way to realize practical mechanisms for privacy-preserving deep learning. However, as shown in our work, we still require significant improvements to achieve meaningful utility for privacy budgets where we have strong theoretical guarantees. Concurrently, the huge gap between the empirical privacy leakage and the theoretical bounds opens the possibility for more powerful inference attacks in practice.&lt;/p&gt;

&lt;h2 id=&#34;additional-results-in-the-paper&#34;&gt;Additional Results in the Paper&lt;/h2&gt;

&lt;p&gt;While we only discussed selected results in this blog post, the &lt;a href=&#34;https://www.cs.virginia.edu/~evans/pubs/usenix2019/evaluatingdp.pdf&#34; target=&#34;_blank&#34;&gt;full paper&lt;/a&gt; has more experimental results across different settings as listed below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Results on Purchase-100 data set, derived from &lt;a href=&#34;https://www.kaggle.com/c/acquire-valued-shoppers-challenge/data&#34; target=&#34;_blank&#34;&gt;Kaggle&lt;/a&gt; website.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Results for logistic regression model.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Membership inference attack of &lt;a href=&#34;https://arxiv.org/pdf/1610.05820.pdf&#34; target=&#34;_blank&#34;&gt;Shokri et al.&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Attribute inference attack of &lt;a href=&#34;https://arxiv.org/pdf/1709.01604.pdf&#34; target=&#34;_blank&#34;&gt;Yeom et al&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://bargavjayaraman.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/slides/example/</guid>
      <description>

&lt;h1 id=&#34;welcome-to-slides&#34;&gt;Welcome to Slides&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34;&gt;Academic&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;

&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code block:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;

&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;

&lt;p&gt;Block math:&lt;/p&gt;

&lt;p&gt;$$
f\left( x \right) = \;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;

&lt;p&gt;Make content appear incrementally&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
   One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three
&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;

&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;

&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;
&lt;/aside&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;


&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;


&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;

&lt;p&gt;Customize the slide style and background&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;

&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://discourse.gohugo.io&#34; target=&#34;_blank&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://sourcethemes.com/academic/docs/&#34; target=&#34;_blank&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Analysis of Private ML Models</title>
      <link>https://bargavjayaraman.github.io/project/evaluating-dpml/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/project/evaluating-dpml/</guid>
      <description>&lt;p&gt;Machine learning models are being extensively trained on sensitive human data (such as pictures, videos and patient health records) and are being publicly deployed as a service. With such systems in  place, privacy of the individuals involved in the model training becomes a real concern. While differential privacy provides a solution to this problem, there is always a privacy-utility trade-off when training models privately, which is not well understood. Often the practical deployments choose the model utility over privacy, that may lead to indiscernable privacy vulnerabilities. One such example of privacy vulnerability is whether an adversary can identify a particular individual in the training data. Also, what type of individuals are more vulnerable to such attacks? This question is also directly related to the problem of fairness. In light of such vulnerabilities, what privacy parameters should the ML deployments use to mitigate the risks? Our project tries to shed light on these questions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting Vague Words and Phrases in Requirements Documents in a Multilingual Environment</title>
      <link>https://bargavjayaraman.github.io/publication/vagueness/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/vagueness/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Decentralized Certificate Authorities</title>
      <link>https://bargavjayaraman.github.io/publication/dca/</link>
      <pubDate>Sun, 11 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/dca/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Decentralized Certificate Authorities</title>
      <link>https://bargavjayaraman.github.io/project/dca/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/project/dca/</guid>
      <description>&lt;p&gt;Certificate authorities have a single point of failure in signing the digital certificates &amp;ndash; what if their signing key gets stolen? This is possible if the signing key is stored on a single machine. Instead, we propose secret sharing of signing keys across multiple machines such that the certificate authorites can combine the secret shares within the multi-party computation protocol and sign the digital certificate in an encrypted way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Aggregating Private Sparse Learning Models Using Multi-Party Computation</title>
      <link>https://bargavjayaraman.github.io/publication/model-aggregation/</link>
      <pubDate>Sun, 04 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/model-aggregation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privacy Preserving Machine Learning</title>
      <link>https://bargavjayaraman.github.io/project/ppml/</link>
      <pubDate>Sat, 03 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/project/ppml/</guid>
      <description>&lt;p&gt;Multi-party computation protocols provide computational security to both data and model through encrypted computations. Differential privacy, on the other hand, provides information theoretic privacy by perturbing the computations with noise. These techniques consider a different threat model and have orthogonal goals. In this project, we combine both technuqies to achieve strong security and privacy for machine learning on sensitive data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Preserving String Matching for Cloud Computing</title>
      <link>https://bargavjayaraman.github.io/publication/searchable-encryption/</link>
      <pubDate>Mon, 29 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/searchable-encryption/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
