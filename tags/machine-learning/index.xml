<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Bargav Jayaraman</title>
    <link>https://bargavjayaraman.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Bargav Jayaraman</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Aug 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://bargavjayaraman.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Evaluating Differentially Private Machine Learning in Practice</title>
      <link>https://bargavjayaraman.github.io/publication/evaluating-dpml/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/evaluating-dpml/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/JAGhqbY_U50&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization</title>
      <link>https://bargavjayaraman.github.io/publication/dp-erm/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/dp-erm/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/rwyWiDyVmjE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Analysis of Private ML Models</title>
      <link>https://bargavjayaraman.github.io/project/evaluating-dpml/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/project/evaluating-dpml/</guid>
      <description>&lt;p&gt;Machine learning models are being extensively trained on sensitive human data (such as pictures, videos and patient health records) and are being publicly deployed as a service. With such systems in  place, privacy of the individuals involved in the model training becomes a real concern. While differential privacy provides a solution to this problem, there is always a privacy-utility trade-off when training models privately, which is not well understood. Often the practical deployments choose the model utility over privacy, that may lead to indiscernable privacy vulnerabilities. One such example of privacy vulnerability is whether an adversary can identify a particular individual in the training data. Also, what type of individuals are more vulnerable to such attacks? This question is also directly related to the problem of fairness. In light of such vulnerabilities, what privacy parameters should the ML deployments use to mitigate the risks? Our project tries to shed light on these questions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting Vague Words and Phrases in Requirements Documents in a Multilingual Environment</title>
      <link>https://bargavjayaraman.github.io/publication/vagueness/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/vagueness/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aggregating Private Sparse Learning Models Using Multi-Party Computation</title>
      <link>https://bargavjayaraman.github.io/publication/model-aggregation/</link>
      <pubDate>Sun, 04 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/publication/model-aggregation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privacy Preserving Machine Learning</title>
      <link>https://bargavjayaraman.github.io/project/ppml/</link>
      <pubDate>Sat, 03 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/project/ppml/</guid>
      <description>&lt;p&gt;Multi-party computation protocols provide computational security to both data and model through encrypted computations. Differential privacy, on the other hand, provides information theoretic privacy by perturbing the computations with noise. These techniques consider a different threat model and have orthogonal goals. In this project, we combine both technuqies to achieve strong security and privacy for machine learning on sensitive data.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
