<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Multi-Party Computation on Bargav Jayaraman</title>
    <link>https://bargavjayaraman.github.io/tags/multi-party-computation/</link>
    <description>Recent content in Multi-Party Computation on Bargav Jayaraman</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Mar 2017 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://bargavjayaraman.github.io/tags/multi-party-computation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Decentralized Certificate Authorities</title>
      <link>https://bargavjayaraman.github.io/project/dca/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/project/dca/</guid>
      <description>&lt;p&gt;Certificate authorities have a single point of failure in signing the digital certificates &amp;ndash; what if their signing key gets stolen? This is possible if the signing key is stored on a single machine. Instead, we propose secret sharing of signing keys across multiple machines such that the certificate authorites can combine the secret shares within the multi-party computation protocol and sign the digital certificate in an encrypted way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Preserving Machine Learning</title>
      <link>https://bargavjayaraman.github.io/project/ppml/</link>
      <pubDate>Sat, 03 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://bargavjayaraman.github.io/project/ppml/</guid>
      <description>&lt;p&gt;Multi-party computation protocols provide computational security to both data and model through encrypted computations. Differential privacy, on the other hand, provides information theoretic privacy by perturbing the computations with noise. These techniques consider a different threat model and have orthogonal goals. In this project, we combine both technuqies to achieve strong security and privacy for machine learning on sensitive data.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
