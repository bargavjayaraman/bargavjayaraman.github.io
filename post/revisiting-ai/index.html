<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.1">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Bargav Jayaraman">

  
  
  
    
  
  <meta name="description" content="Models leak distribution information that can be used for attribute inference.">

  
  <link rel="alternate" hreflang="en-us" href="https://bargavjayaraman.github.io/post/revisiting-ai/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.3834c081887e44130d565828d71a7178.css">

  

  
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://bargavjayaraman.github.io/post/revisiting-ai/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Bargav Jayaraman">
  <meta property="og:url" content="https://bargavjayaraman.github.io/post/revisiting-ai/">
  <meta property="og:title" content="Attribute Inference Attacks Pose Distribution Inference Risk to Models | Bargav Jayaraman">
  <meta property="og:description" content="Models leak distribution information that can be used for attribute inference."><meta property="og:image" content="https://bargavjayaraman.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://bargavjayaraman.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2022-12-05T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2022-12-05T00:00:00&#43;00:00">
  

  


  





  <title>Attribute Inference Attacks Pose Distribution Inference Risk to Models | Bargav Jayaraman</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Bargav Jayaraman</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/CV.pdf"><span>CV</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  <article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Attribute Inference Attacks Pose Distribution Inference Risk to Models</h1>

  

  
    



<meta content="2022-12-05 00:00:00 &#43;0000 UTC" itemprop="datePublished">
<meta content="2022-12-05 00:00:00 &#43;0000 UTC" itemprop="dateModified">

<div class="article-metadata">

  
  
  
  
  <div>
    



  <span itemprop="author name" itemtype="http://schema.org/Person"><a href="/authors/admin/">Bargav Jayaraman</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    <time>Dec 5, 2022</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  

  
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://bargavjayaraman.github.io/post/revisiting-ai/&amp;text=Attribute%20Inference%20Attacks%20Pose%20Distribution%20Inference%20Risk%20to%20Models" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://bargavjayaraman.github.io/post/revisiting-ai/&amp;t=Attribute%20Inference%20Attacks%20Pose%20Distribution%20Inference%20Risk%20to%20Models" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Attribute%20Inference%20Attacks%20Pose%20Distribution%20Inference%20Risk%20to%20Models&amp;body=https://bargavjayaraman.github.io/post/revisiting-ai/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://bargavjayaraman.github.io/post/revisiting-ai/&amp;title=Attribute%20Inference%20Attacks%20Pose%20Distribution%20Inference%20Risk%20to%20Models" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Attribute%20Inference%20Attacks%20Pose%20Distribution%20Inference%20Risk%20to%20Models%20https://bargavjayaraman.github.io/post/revisiting-ai/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://bargavjayaraman.github.io/post/revisiting-ai/&amp;title=Attribute%20Inference%20Attacks%20Pose%20Distribution%20Inference%20Risk%20to%20Models" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

    













<div class="btn-links mb-3">
  
  








  









  
  <a class="btn btn-outline-primary my-1 mr-1" href="/project/evaluating-dpml/">
    Project
  </a>
  











</div>


  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<p><center>
<img alt="" src="img/ai.png" width="80%">
</center></p>

<p><em>Attribute inference</em> attacks have been shown by prior works to pose privacy threat against ML models. However, these works assume the knowledge of the training distribution and we show that in such cases these attacks do no better than a data imputataion attack that does not have access to the model. We explore the attribute inference risks in the cases where the adversary has limited or no prior knowledge of the training distribution and show that our white-box attribute inference attack (that uses neuron activations to infer the unknown sensitive attribute) surpasses imputation in these data constrained cases. This attack uses the training distribution information leaked by the model, and thus poses privacy risk when the distribution is private.</p>

<h2 id="prior-attribute-inference-attacks-do-not-pose-privacy-risk">Prior Attribute Inference Attacks Do Not Pose Privacy Risk</h2>

<p>Prior works in attribute inference have mainly considered black-box access to the machine learning model and show successful attribute inference (in terms of attack accuracy) in the case where the adversary has access to the underlying training distribution. Our experiments show that in such cases even an imputation adversary, without access to the model, can achieve high inference accuracy, as shown in the table below:</p>

<table>
<thead>
<tr>
<th align="left"></th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th align="center">Census (Race)</th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th align="center">Texas-100X (Ethnicity)</th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Predict Most Common</td>
<td></td>
<td align="center">0.78</td>
<td></td>
<td align="center">0.72</td>
<td></td>
</tr>

<tr>
<td align="left">Imputation Attack</td>
<td></td>
<td align="center">0.82</td>
<td></td>
<td align="center">0.72</td>
<td></td>
</tr>

<tr>
<td align="left">Yeom et al. Attack</td>
<td></td>
<td align="center">0.65</td>
<td></td>
<td align="center">0.58</td>
<td></td>
</tr>

<tr>
<td align="left">Mehnaz et al. Attack</td>
<td></td>
<td align="center">0.06</td>
<td></td>
<td align="center">0.60</td>
<td></td>
</tr>

<tr>
<td align="left">WCAI (Our version of Yeom)</td>
<td></td>
<td align="center">0.83</td>
<td></td>
<td align="center">0.74</td>
<td></td>
</tr>
</tbody>
</table>

<p><center>Comparing attribute inference accuracy of attacks</center></p>

<p>Thus, these attribute inference attacks seem to not pose any significant privacy risk as the adversary can have similar attack success without access to the model.</p>

<h2 id="sensitive-value-inference">Sensitive Value Inference</h2>

<p>Attribute inference risk is inherently asymmetric&mdash; identifying a record with minority attribute value (such as <em>Hispanic</em> ethnicity) does not have the same risk as identifying a record with majority attribute value (such as <em>Non-Hispanic</em> ethnicity). Accuracy metric does not capture this. Moreover, attribute inference definition considered by prior works also fails to distinguish these cases. We propose studying a fine-grained version of attribute inference, called <em>sensitive value inference</em>, that considers the attack success in inferring a particular sensitive attribute outcome.</p>

<p><center>
<img alt="" src="img/svi.png" width="80%">
</center></p>

<p>We measure the attack success by evaluating the positive predictive value (PPV) of the inference attack in predicting the top-k candidate records with the sensitive outcome. The PPV values are between 0 and 1, where a higher value denotes a greater attack precision.</p>

<h2 id="the-neuron-output-attack">The Neuron Output Attack</h2>

<p>Our novel neuron output based white-box attack finds the neurons that are most correlated with the sensitive value. For this attack, the adversary selects records from a hold-out set, sets the unknown target attribute to the sensitive value, and queries the model. The adversary then identifies the set of neurons that have higher activations on average for the records with the sensitive value as the ground-truth. The adversary then uses the aggregate output of these neurons to identify the candidate records with sensitive value.</p>

<p><center>
<img alt="" src="img/wb.png" width="75%">
</center></p>

<h2 id="model-leaks-distribution-information">Model Leaks Distribution Information</h2>

<p>In our experiments, we vary the distribution available to the adversary and also the amount of data from the respective distribution the adversary has to train the inference attack. When the adversary has access to &gt;5000 records from the training distribition (not the same as the training set records), imputataion outperforms all the attribute inference attacks (incuding our white-box neuron output attack). As we decrease the known set size to 500 and 50, the imputation PPV decreases drastically whereas our neuron output attack continues to achieve high PPV. Thus the attack is able to take advantage of the training distribution information leaked by the model. The figure below depicts the case where the adversary has 500 records from the training distribution, and as shown, the neuron output attack surpasses the imputataion.</p>

<p><center>
<img alt="" src="img/img2.png" width="100%">
<div class="caption">
Neurons correlated to Hispanic ethnicity for a neural network model trained on Texas-100X data set.
</div>
</center></p>

<p>We observe similar trend across different distribution settings and across different data sets. Detailed results can be found in the paper.</p>

<h2 id="differential-privacy-doesn-t-mitigate-the-risk">Differential Privacy Doesn&rsquo;t Mitigate the Risk</h2>

<p>Prior attribute inference works have shown that the attribute inference attacks do not work in the cases where membership inference attacks do not succeed. Hence, the prior works&rsquo; claim is that differential privacy mechanisms, that defend against membership inference attacks, also defend against attribute inference attacks. This is based on the <em>attribute advantage</em> metric of Yeom et al. that shows that the difference between the <em>accuracy</em> of inference attack across training and non-training set is bounded by differential privacy. We agree that this is true, as we shown in our experiment results in Table 2 below where the PPV of the neuron output attack is similar across both train and test sets. However, our <em>attribute advantage</em> metric measures the gap between the attack PPV when the adversary has access to the model (i.e., neuron output attack) versus when the adversary does not have model access (i.e., imputataion). As shown in the table below, this is not bounded by differential privacy as the neuron output attack PPV remains more or less the same with or without differential privacy.</p>

<table>
<thead>
<tr>
<th align="left"></th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th align="center">Without DP</th>
<th align="center">With DP</th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th align="center">Train Set</th>
<th align="center">Test Set</th>
<th>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>

<tbody>
<tr>
<td align="left">Imputation Attack</td>
<td></td>
<td align="center">0.62 $\pm$ 0.05</td>
<td align="center">0.62 $\pm$ 0.05</td>
<td></td>
<td align="center">0.62 $\pm$ 0.05</td>
<td align="center">0.63 $\pm$ 0.02</td>
<td></td>
</tr>

<tr>
<td align="left">Neuron Output Attack</td>
<td></td>
<td align="center">0.49 $\pm$ 0.02</td>
<td align="center">0.49 $\pm$ 0.03</td>
<td></td>
<td align="center">0.49 $\pm$ 0.03</td>
<td align="center">0.48 $\pm$ 0.02</td>
<td></td>
</tr>
</tbody>
</table>

<p><center>Impact of Differential Privacy (DP) on the PPV of attacks (see table in paper for error margins). Results show the PPV of attacks in predicting top-100 candidate records.</center></p>

<p>Since the risk is due to the model leaking distribution information, it is not mitigated by differential privacy noise.</p>

<h2 id="conclusion">Conclusion</h2>

<p>We show that the attribute inference attacks take advantage of the model leaking sensitive information about the underlying training distribution as opposed to leaking information about individual training records. While this is often considered by researchers to be <strong>not</strong> a privacy risk since the distribution statistics are supposed to be public knowledge, we argue that when the distribution itself is a private information then any such disclosure poses a severe privacy risk. Existing defenses, such as training the model with differential privacy mechanisms, does not mitigate this distribution privacy risk.</p>

<p><strong>Full paper:</strong> Bargav Jayaraman and David Evans. <a href="https://arxiv.org/abs/2209.01292" target="_blank"><em>Are Attribute Inference Attacks Just Imputation?</em></a> (<a href="https://arxiv.org/abs/2209.01292" target="_blank">arXiv</a>).</p>

<p><strong>Code:</strong> <a href="https://github.com/bargavj/EvaluatingDPML" target="_blank"><em>https://github.com/bargavj/EvaluatingDPML</em></a></p>

<p><strong>Talk Video:</strong> <a href="https://youtu.be/iLy0C5DK2T8" target="_blank"><em>https://youtu.be/iLy0C5DK2T8</em></a></p>

    </div>

    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/machine-learning/">Machine Learning</a>
  
  <a class="badge badge-light" href="/tags/differential-privacy/">Differential Privacy</a>
  
</div>



    
      








  
  
    
  
  





  
  
  
    
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hu562c4626a9025a614c63c0bbb0be2b3c_761363_250x250_fill_q90_lanczos_center.jpg" itemprop="image" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="https://bargavjayaraman.github.io/">Bargav Jayaraman</a></h5>
      <h6 class="card-subtitle">PhD in Computer Science</h6>
      <p class="card-text" itemprop="description">My research interests include machine learning and privacy.</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
          <li>
            <a itemprop="sameAs" href="mailto:bargavjayaraman@gmail.com" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://www.linkedin.com/in/bargav-jayaraman/" target="_blank" rel="noopener">
              <i class="fab fa-linkedin"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://scholar.google.co.in/citations?user=gL3ZkpEAAAAJ&amp;hl=en" target="_blank" rel="noopener">
              <i class="ai ai-google-scholar"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/bargavjayaraman" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/bargavj" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="/files/CV.pdf" >
              <i class="ai ai-cv"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/publication/revisiting-ai/">Are Attribute Inference Attacks Just Imputation?</a></li>
          
          <li><a href="/publication/smart-reply-attack/">Combing for Credentials: Active Pattern Extraction from Smart Reply</a></li>
          
          <li><a href="/post/ai_defense_results/">Defense Against Attribute Inference</a></li>
          
          <li><a href="/post/revisiting-mi/">Merlin, Morgan, and the Importance of Thresholds and Priors</a></li>
          
          <li><a href="/publication/nonconvex-optimization/">Efficient Privacy-Preserving Nonconvex Optimization</a></li>
          
        </ul>
      </div>
      
    

    

    


  </div>
</article>

      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.98ea4faec9c45f666e4a8a91902fa456.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
